{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training code source: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "model_name = \"vgg\" # Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "input_size = 48\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and transformsvalidation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "            \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # 3 x 48 x 48 input\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=5, stride=2, padding=0),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 128),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(128, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(-1, 16 * 4 * 4)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t layer1.0.weight\n",
      "\t layer1.0.bias\n",
      "\t layer2.0.weight\n",
      "\t layer2.0.bias\n",
      "\t layer3.0.weight\n",
      "\t layer3.0.bias\n",
      "\t layer4.0.weight\n",
      "\t layer4.0.bias\n",
      "\t layer5.0.weight\n",
      "\t layer5.0.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "for name, param in model_ft.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.4172\n",
      "val Loss: 0.6963 Acc: 0.3708\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.6892 Acc: 0.5598\n",
      "val Loss: 0.6808 Acc: 0.6231\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.6826 Acc: 0.5839\n",
      "val Loss: 0.6728 Acc: 0.6231\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.6791 Acc: 0.5839\n",
      "val Loss: 0.6683 Acc: 0.6231\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.6759 Acc: 0.5839\n",
      "val Loss: 0.6635 Acc: 0.6231\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.5839\n",
      "val Loss: 0.6561 Acc: 0.6231\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.6623 Acc: 0.5839\n",
      "val Loss: 0.6427 Acc: 0.6231\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.5839\n",
      "val Loss: 0.6154 Acc: 0.6231\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.6157 Acc: 0.5817\n",
      "val Loss: 0.5767 Acc: 0.6170\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.5882 Acc: 0.6064\n",
      "val Loss: 0.5472 Acc: 0.6413\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.5754 Acc: 0.6305\n",
      "val Loss: 0.5358 Acc: 0.6869\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.5711 Acc: 0.6475\n",
      "val Loss: 0.5274 Acc: 0.6900\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.5676 Acc: 0.6562\n",
      "val Loss: 0.5232 Acc: 0.6960\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.5650 Acc: 0.6552\n",
      "val Loss: 0.5158 Acc: 0.7082\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.5612 Acc: 0.6672\n",
      "val Loss: 0.5135 Acc: 0.7143\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.5570 Acc: 0.6721\n",
      "val Loss: 0.5061 Acc: 0.7173\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.5529 Acc: 0.6765\n",
      "val Loss: 0.5026 Acc: 0.7204\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.5471 Acc: 0.6804\n",
      "val Loss: 0.4943 Acc: 0.7325\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.5405 Acc: 0.6957\n",
      "val Loss: 0.4850 Acc: 0.7325\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.5293 Acc: 0.7061\n",
      "val Loss: 0.4766 Acc: 0.7568\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.5161 Acc: 0.7264\n",
      "val Loss: 0.4592 Acc: 0.8085\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.5060 Acc: 0.7330\n",
      "val Loss: 0.4472 Acc: 0.7903\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.4759 Acc: 0.7714\n",
      "val Loss: 0.4231 Acc: 0.8085\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.4484 Acc: 0.7999\n",
      "val Loss: 0.3942 Acc: 0.8389\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.4283 Acc: 0.8158\n",
      "val Loss: 0.3720 Acc: 0.8663\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.4269 Acc: 0.7939\n",
      "val Loss: 0.4271 Acc: 0.7933\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.4030 Acc: 0.8251\n",
      "val Loss: 0.3545 Acc: 0.8541\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.3842 Acc: 0.8355\n",
      "val Loss: 0.3971 Acc: 0.8085\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.3989 Acc: 0.8109\n",
      "val Loss: 0.3790 Acc: 0.8359\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.3680 Acc: 0.8476\n",
      "val Loss: 0.3217 Acc: 0.8723\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.3448 Acc: 0.8646\n",
      "val Loss: 0.3346 Acc: 0.8267\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.3340 Acc: 0.8531\n",
      "val Loss: 0.3761 Acc: 0.8298\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.3664 Acc: 0.8372\n",
      "val Loss: 0.3254 Acc: 0.8571\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.3435 Acc: 0.8591\n",
      "val Loss: 0.2875 Acc: 0.8967\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.3169 Acc: 0.8668\n",
      "val Loss: 0.2901 Acc: 0.8967\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.3103 Acc: 0.8832\n",
      "val Loss: 0.3074 Acc: 0.8723\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.3044 Acc: 0.8745\n",
      "val Loss: 0.3175 Acc: 0.8480\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.2919 Acc: 0.8734\n",
      "val Loss: 0.2614 Acc: 0.9088\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.2939 Acc: 0.8755\n",
      "val Loss: 0.3010 Acc: 0.8906\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.3038 Acc: 0.8695\n",
      "val Loss: 0.2517 Acc: 0.9088\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.2797 Acc: 0.8942\n",
      "val Loss: 0.2416 Acc: 0.9088\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.2748 Acc: 0.8882\n",
      "val Loss: 0.2664 Acc: 0.8906\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.2731 Acc: 0.8887\n",
      "val Loss: 0.2418 Acc: 0.9058\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.2566 Acc: 0.8975\n",
      "val Loss: 0.2282 Acc: 0.9119\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.2532 Acc: 0.8958\n",
      "val Loss: 0.2414 Acc: 0.9088\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.2496 Acc: 0.9024\n",
      "val Loss: 0.2990 Acc: 0.8541\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.2731 Acc: 0.8827\n",
      "val Loss: 0.2469 Acc: 0.9119\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.2479 Acc: 0.8997\n",
      "val Loss: 0.2333 Acc: 0.8997\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.2503 Acc: 0.8898\n",
      "val Loss: 0.2369 Acc: 0.9119\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.2425 Acc: 0.9079\n",
      "val Loss: 0.2418 Acc: 0.8845\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.2370 Acc: 0.8991\n",
      "val Loss: 0.2334 Acc: 0.8997\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.2342 Acc: 0.9057\n",
      "val Loss: 0.2512 Acc: 0.8754\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.2305 Acc: 0.9019\n",
      "val Loss: 0.2300 Acc: 0.9058\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.2448 Acc: 0.8953\n",
      "val Loss: 0.2298 Acc: 0.9058\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.2406 Acc: 0.8997\n",
      "val Loss: 0.2414 Acc: 0.8967\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.2318 Acc: 0.9030\n",
      "val Loss: 0.2573 Acc: 0.8845\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.2445 Acc: 0.8980\n",
      "val Loss: 0.2807 Acc: 0.8632\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.2217 Acc: 0.9041\n",
      "val Loss: 0.2249 Acc: 0.9210\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.2108 Acc: 0.9134\n",
      "val Loss: 0.2255 Acc: 0.9027\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.2107 Acc: 0.9172\n",
      "val Loss: 0.2390 Acc: 0.8967\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.2122 Acc: 0.9079\n",
      "val Loss: 0.2185 Acc: 0.9088\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.2044 Acc: 0.9161\n",
      "val Loss: 0.2078 Acc: 0.9149\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.2095 Acc: 0.9134\n",
      "val Loss: 0.2335 Acc: 0.9088\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.2113 Acc: 0.9145\n",
      "val Loss: 0.2166 Acc: 0.9119\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.1906 Acc: 0.9232\n",
      "val Loss: 0.2152 Acc: 0.9088\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.1977 Acc: 0.9183\n",
      "val Loss: 0.2080 Acc: 0.9119\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.1965 Acc: 0.9161\n",
      "val Loss: 0.2022 Acc: 0.9210\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.1987 Acc: 0.9211\n",
      "val Loss: 0.2159 Acc: 0.9088\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.1969 Acc: 0.9205\n",
      "val Loss: 0.2087 Acc: 0.9210\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.1949 Acc: 0.9172\n",
      "val Loss: 0.2742 Acc: 0.8693\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.2048 Acc: 0.9101\n",
      "val Loss: 0.2108 Acc: 0.9027\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.2039 Acc: 0.9134\n",
      "val Loss: 0.2415 Acc: 0.8967\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.1946 Acc: 0.9178\n",
      "val Loss: 0.2668 Acc: 0.8936\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9156\n",
      "val Loss: 0.2078 Acc: 0.9119\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.1897 Acc: 0.9194\n",
      "val Loss: 0.2183 Acc: 0.9088\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.1755 Acc: 0.9243\n",
      "val Loss: 0.2065 Acc: 0.9088\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.1804 Acc: 0.9260\n",
      "val Loss: 0.2074 Acc: 0.9240\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.1685 Acc: 0.9326\n",
      "val Loss: 0.2069 Acc: 0.9088\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.1798 Acc: 0.9254\n",
      "val Loss: 0.2237 Acc: 0.9179\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.1929 Acc: 0.9112\n",
      "val Loss: 0.2467 Acc: 0.8936\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.1809 Acc: 0.9216\n",
      "val Loss: 0.2715 Acc: 0.8875\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.1777 Acc: 0.9232\n",
      "val Loss: 0.2254 Acc: 0.9027\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.1846 Acc: 0.9216\n",
      "val Loss: 0.2006 Acc: 0.9119\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.1661 Acc: 0.9287\n",
      "val Loss: 0.2087 Acc: 0.9119\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.1633 Acc: 0.9276\n",
      "val Loss: 0.2022 Acc: 0.9119\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.1642 Acc: 0.9265\n",
      "val Loss: 0.1946 Acc: 0.9240\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.1665 Acc: 0.9315\n",
      "val Loss: 0.1935 Acc: 0.9271\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9326\n",
      "val Loss: 0.2774 Acc: 0.8845\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.1732 Acc: 0.9227\n",
      "val Loss: 0.2209 Acc: 0.9088\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.1733 Acc: 0.9282\n",
      "val Loss: 0.2138 Acc: 0.9179\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.1566 Acc: 0.9309\n",
      "val Loss: 0.1969 Acc: 0.9149\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9380\n",
      "val Loss: 0.1907 Acc: 0.9240\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.1542 Acc: 0.9304\n",
      "val Loss: 0.1958 Acc: 0.9119\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.1543 Acc: 0.9359\n",
      "val Loss: 0.1896 Acc: 0.9271\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9359\n",
      "val Loss: 0.1937 Acc: 0.9179\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.1510 Acc: 0.9359\n",
      "val Loss: 0.1856 Acc: 0.9179\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9287\n",
      "val Loss: 0.2505 Acc: 0.8845\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.1629 Acc: 0.9298\n",
      "val Loss: 0.2095 Acc: 0.9027\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1498 Acc: 0.9380\n",
      "val Loss: 0.2051 Acc: 0.9240\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.1358 Acc: 0.9474\n",
      "val Loss: 0.2139 Acc: 0.9331\n",
      "\n",
      "Training complete in 0m 41s\n",
      "Best val Acc: 0.933131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)\n",
    "torch.save(model_ft, 'models/cow_classifer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb8c3a4550>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(hist)), hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
